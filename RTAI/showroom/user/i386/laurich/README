Here we have a rewrite of the code used in an infamous publication appeared
on Linuxdevices.com. Such a publication wrongly stated that LXRT was not
for real time. This rewrite maintains all the features of the code used for
it, which was related to a particular hardware, while being executable on
any PC.
With this rewrite it is clearly possible to prove that LXRT was not used
correctly, i.e. it was used in soft mode, but we profit of it for showing also
the limitations of general CPUs (GCPU) for real time and how one should be
carefull on stating what part of the scheduling latency is due to RTAI and
what not.

It is well known that latencies on GCPUs can vary widely in relation to many
architectural factors. For a few checks related to what above this test can
be executed in different modes, according to the following macros, defined in
lxrtext.h.


DISABLE_IRQ

Profits of the x86 possibility of disabling interrupts by anybody, everywhere.
This verifies that a relatively high latency can exist even if no interrupt
can occur on the path back to the task from the interrupt handler, which is
entered with all interrupts disabled from the very istant in which the CPU
acknowledges it in hardware. Notice that by executing with this macro you'll
avoid any doubt that scheduling latencies could build up because of the need
of registering any Linux interrupt that might come in after the process has
resumed in kernel, but before returning to user space.


USE_EXT_WAIT

Returns all the times needed to measure scheduling latencies, taking them in
kernel space directly, i.e. after the process has been fully resumed but just
before returning to user space. The only difference with respect to not using
it, i.e. by doing a subsequent specific call from the process to get those
times, is that it avoids going back and forth user/kernel space just to read
the timer. The differences from having this macro enabled or not far exceeds
the back/forth time, a worst case measure of which is a full task switching,
as measured from the "switches" test, plus adding the interrupts time penalty
that must be paid to pend any Linux own interrupt that might happen in between.


By combining the above two macros one can see that GPCPUs do have an intrinsic
architectural limitations for real time, far exceeding any difference in bad
and good coding and the relatively high cost of accessing any bus.

All the timing is based on reading the counter of a recicling periodic timer,
8254, so that latencies can be measured from the very instant the timer
interrupt was physically triggered.

However at the handler module removal the average times taken (as determined
by reading the TSC):
- to read the 8254 timer,
- from the interrupt handler entering to sem signal,
- from the interrupt handler entering to returning from sem wait in kernel,
are printed, so that the some timing of the main phases of the latency build
up should be available for comparison.

To be noticed the disproportionate time required to read and ack the timer and
the execution time of the irq handler, far higher than an estimate inferred
by symming the CPU time of the number of instructions to be executed, even
when interrupts are kept fully disabled till user space is reached. In any
case the whole worst case scheduling latency will far exceed the average,
even executing with interrupts disabled and that, again, is due to the
hardware architecture.

The above cited intermediate measures clearly add some latency of their own,
because of the TSC readings and some added "long long" calculations. Such a
penalty is nonetheless negligeable for sure.

Overall this is not a good way to measure RTAI related scheduling latencies
because of the continuous readings of 8254 and because a large part of the
scheduling latency itself is within the execution of the handler which, as
said above, is too much just because of the reading of 8254 and the, useless,
rt_ack_irq used. Just by commenting out the irq ack the execution time of the
irq handler decreases substantially.

RTAI users should trust the standard testsuite latency check much more, after
all it too does nothing but resuming from a timer interrrupt.
